# Matrix Multiplication

Потыкаться в программе можно **[тут](https://colab.research.google.com/drive/1FUyUZJEdpSXz3GkS_2B9Tkmc4mj4NwWl?usp=sharing)**

Для умножения двух матриц типа **double** была реализована функция **_gpu_blas_mmul_**, которая использует функцию **_cublasDgemm_** из библиотеки **Cublas**. Функция **_cublasDgemm_** в своей сигнатуре требует объект **cublasHandle_t handle**, который отвечает за подбор оптимальных **GRID_SIZE** и **BLOCK_SIZE**.

#### Принцип распараллеливания вычислений заключается в том, что каждое **cuda ядро** вычисляет свою ячейку результирующей матрицы **C**.

Последовательность работы программы:
1. Изначально матрицы А и B заполняются псевдорандомнычи числами от 0 до 1 на GPU с использованием функции **curandGenerateUniformDouble** из библиотеки **Cublas**.
2. Затем матрицы А и B копируются из памяти девайса (GPU) в память хоста, чтобы мы могли их вывести в консоль или использовать для вызова последовательного умножения матриц на CPU.
3. Вызывается функция умножения матриц на GPU: "gpu_blas_mmul(d_A, d_B, d_C, nr_rows_A, nr_cols_A, nr_cols_B);"
4. Вызывается функия умножения матриц на CPU:
"cpu_mmul(h_A, h_B, cpu_C, N);"
5. Вычисляется разность между матрицой С, вычисленной на GPU, и матрицой C, вычисленной на CPU (ака. проверка корректности умножения).
6. Вывод результатов.

### Графики времени выполнения и ускорения:

![Графики времени выполнения и ускорения](https://github.com/KhoroshevDaniil/HPC_2023/blob/main/MatrixMultiplication/%D0%B3%D1%80%D0%B0%D1%84%D0%B8%D0%BA%D0%B8.png)
